{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install Essential Package","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installation of packages\n!pip install wget","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports of libraries\nfrom plotly.subplots import make_subplots\nfrom urllib.request import urlopen\nfrom datetime import date, timedelta\nimport plotly.express as px\nimport pandas as pd \nimport numpy as np\nimport warnings\nimport datetime\nimport folium\nimport json\nimport wget\nimport os\n    \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove old csv data files (if any)\n! rm *.csv\n\n# Download latest data files from John Hopkins datasets and other essential datasets\nurls = [\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\",\n        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\",\n        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\",\n        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\",\n        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\"]\n\nfor url in urls:\n    wget.download(url)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Global Stats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframes from the files\nconfirmed_wide = pd.read_csv(\"./time_series_covid19_confirmed_global.csv\")\ndeceased_wide = pd.read_csv(\"./time_series_covid19_deaths_global.csv\")\nrecovered_wide = pd.read_csv(\"time_series_covid19_recovered_global.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_wide","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshaping dataframe. Converting Date representing columns and their values into separate column \nconfirmedDF = pd.melt(confirmed_wide, id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"],\n                           var_name=\"Date\", value_name=\"Confirmed\")\ndeceasedDF = pd.melt(deceased_wide, id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"],\n                           var_name=\"Date\", value_name=\"Deceased\")\nrecoveredDF = pd.melt(recovered_wide, id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"],\n                           var_name=\"Date\", value_name=\"Recovered\")\n\nprint(\"confirmedDF Shape: \", confirmedDF.shape)\nprint(\"deceasedDF Shape: \", deceasedDF.shape)\nprint(\"recoveredDF Shape: \", recoveredDF.shape)\nconfirmedDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging all the dataframes into one\ntotalDF = pd.merge(left=confirmedDF, right=deceasedDF, how='outer', \n                   on=[\"Province/State\", \"Country/Region\", \"Date\", \"Lat\", \"Long\"])\ntotalDF = pd.merge(left=totalDF, right=recoveredDF, on=[\"Province/State\", \"Country/Region\", \"Date\", \"Lat\", \"Long\"],\n                  how='outer')\ntotalDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count total current NaN values\nprint(\"Before NaN removal:\")\nprint(totalDF.isna().sum())\nprint()\n\n# Removing all NaN values\ntotalDF[\"Confirmed\"] = totalDF[\"Confirmed\"].fillna(0)\ntotalDF[\"Deceased\"] = totalDF[\"Deceased\"].fillna(0)\ntotalDF[\"Recovered\"] = totalDF[\"Recovered\"].fillna(0)\ntotalDF.isna().sum()\n\nprint(\"After NaN removal:\")\nprint(totalDF.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print all Countries \ntotalDF[\"Country/Region\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the Date column into proper datetime formate and sort\ntotalDF.Date = pd.to_datetime(totalDF.Date)\ntotalDF.sort_values(by=[\"Date\"], inplace=True)\ntotalDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe for frequency of cases based on Recorvered, Confirmed and Deceased\ndate_groupedDF = totalDF.groupby('Date')['Recovered', 'Confirmed', 'Deceased'].sum().reset_index()\ndate_groupedDF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Color pallete\nRecovered, Confirmed, Deceased = '#28a745', '#007bff', '#ff073a'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Line Tree Map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = date_groupedDF[date_groupedDF['Date']==max(date_groupedDF['Date'])].reset_index(drop=True)\n\nmelted_temp = temp.melt(id_vars=\"Date\", value_vars=['Recovered', 'Confirmed', 'Deceased'])\nfig = px.treemap(melted_temp, path=[\"variable\"], values=\"value\", height=250, width=1200,\n                 color_discrete_sequence=[Recovered, Confirmed, Deceased])\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pie Chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(melted_temp, values=\"value\", height=750, names='variable', title='Covid 19',\n                 color_discrete_sequence=[Recovered, Confirmed, Deceased])\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Area Chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating columns to indicate case type and frequency based on the Date\ndate_countDF = date_groupedDF.melt(id_vars=['Date'], var_name='Case Type', value_name='Frequency')\n\nfig = px.area(date_countDF, x='Date', y='Frequency', title='Cases Over Time Slider', \n              color='Case Type', color_discrete_sequence=[Recovered, Confirmed, Deceased])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating bar graphs\nfig1 = px.bar(date_groupedDF, x=\"Date\", y=\"Confirmed\", color_discrete_sequence=[Confirmed])\nfig2 = px.bar(date_groupedDF, x=\"Date\", y=\"Deceased\", color_discrete_sequence=[Deceased])\nfig3 = px.bar(date_groupedDF, x=\"Date\", y=\"Recovered\", color_discrete_sequence=[Recovered])\n\nfig = make_subplots(rows=2, cols=2,shared_xaxes=False, horizontal_spacing=0.1, vertical_spacing=0.1,\n                   subplot_titles=(\"Confirmed Cases\", \"Deceased Cases\", \"Recovered Cases\"))\n\nfig.add_trace(fig1['data'][0], row=1, col=1)\nfig.add_trace(fig2['data'][0], row=1, col=2)\nfig.add_trace(fig3['data'][0], row=2, col=1)\n\nfig.update_layout(height=700, title='Day Wise Cases')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart Logarithm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logarithm graphs\nfig1 = px.bar(date_groupedDF, x='Date', y='Confirmed', color_discrete_sequence=[Confirmed])\nfig2 = px.bar(date_groupedDF, x='Date', y='Deceased', color_discrete_sequence=[Deceased])\nfig3 = px.bar(date_groupedDF, x='Date', y='Recovered', color_discrete_sequence=[Recovered])\n\nfig = make_subplots(rows=2, cols=2, shared_xaxes=False, horizontal_spacing=0.1, \n                    subplot_titles=(\"Confirmed Cases\", \"Deceased Cases\", \"Recovered Cases\"))\n\nfig.add_trace(fig1['data'][0], row=1, col=1)\nfig.add_trace(fig2['data'][0], row=1, col=2)\nfig.add_trace(fig3['data'][0], row=2, col=1)\n\nfig.update_layout(height=800, yaxis_type='log', yaxis2_type='log', yaxis3_type='log', title='Day Wise Cases(Log Scale)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Maps","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases Map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieving only latest date data from the dataframe\ntemp = totalDF[totalDF['Date'] == max(totalDF['Date'])]\n_map = folium.Map(location=[0,0], tiles='cartodbpositron',\n                 min_zoom=1, max_zoon=4, zoom_start=1.5)\n\nfor i in range(len(temp)):\n    folium.Circle(\n            location=[temp.iloc[i]['Lat'], temp.iloc[i]['Long']],\n            color=Confirmed, fill='crimson',\n            tooltip =   '<li> Country: ' + str(temp.iloc[i]['Country/Region']) +\n                        '<li> Confirmed: ' + str(temp.iloc[i]['Confirmed']) +\n                        '<li> Deceased: ' + str(temp.iloc[i]['Deceased']) +\n                        '<li> Recovered: ' + str(temp.iloc[i]['Recovered']),\n            radius=int(temp.iloc[i]['Confirmed'])//2).add_to(_map)\n_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deceased Cases Map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieving only latest date data from the dataframe\ntemp = totalDF[totalDF['Date'] == max(totalDF['Date'])]\n_map = folium.Map(location=[0,0], tiles='cartodbpositron',\n                 min_zoom=1, max_zoon=4, zoom_start=1.5)\n\nfor i in range(len(temp)):\n    folium.Circle(\n            location=[temp.iloc[i]['Lat'], temp.iloc[i]['Long']],\n            color=Deceased, fill='crimson',\n            tooltip =   '<li> Country: ' + str(temp.iloc[i]['Country/Region']) +\n                        '<li> Confirmed: ' + str(temp.iloc[i]['Confirmed']) +\n                        '<li> Deceased: ' + str(temp.iloc[i]['Deceased']) +\n                        '<li> Recovered: ' + str(temp.iloc[i]['Recovered']),\n            radius=int(temp.iloc[i]['Deceased'])**1.2).add_to(_map)\n_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# US Based Stats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataframes for US datasets\nus_confirmed = pd.read_csv(\"./time_series_covid19_confirmed_US.csv\")\nus_deceased = pd.read_csv(\"./time_series_covid19_deaths_US.csv\")\n\n# We are importing two datasets for population county wise because\n# For visualization, we need 5 figure FIPS which are missing in us_population but gives more accurate measure of counties\n# On the other hand, us_county has consistent 5 figure FIPS which will be used to correct us_population FIPS later. \nus_population = pd.read_csv(\"../input/covid19county/covid_county_population_usafacts.csv\")\nheaders = ['idx', 'FIPS', 'County Name', 'State']\ndtypes = {'idx': 'str', 'FIPS': 'str', 'County Name': 'str', 'State': 'str'}\nus_county = pd.read_csv(\"../input/usa-county-info/usa_county_info\", header=0, names=headers, dtype=dtypes)\nus_county.drop(columns=['idx'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_confirmed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_deceased.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_population","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_county","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Printing some useful stats","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"us_confirmed shape\", us_confirmed.shape)\nprint(\"us_deceased shape\", us_deceased.shape)\nprint(\"us_population shape\", us_population.shape)\nprint(\"us_county shape\", us_county.shape, '\\n')\n\nprint(\"Fips in confirmed: \", len(us_confirmed.FIPS.unique()))\nprint(\"Fips in deceased: \", len(us_deceased.FIPS.unique()))\nprint(\"Fips in population data: \", len(us_population.countyFIPS.unique()))\nprint(\"Fips in us_county data: \", len(us_county.FIPS.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping Unwanted Columns\nnon_usable_columns = [\"UID\", \"iso2\", \"iso3\", \"code3\", \"Admin2\", \"Province_State\", \"Country_Region\", \"Lat\", \"Long_\", \"Combined_Key\"]\nus_confirmed = us_confirmed.drop(columns = non_usable_columns)\n\n# There is an extra column in deceased dataframe named Population. \n# We have to remove that as well since we are taking population data from an entire new data frame\nus_deceased = us_deceased.drop(columns = non_usable_columns + [\"Population\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing all NaN values\nprint(\"Initially Total NaN count:\")\nprint(\"us_confirmed = \", us_confirmed.FIPS.isna().sum())\nprint(\"us_deceased = \", us_deceased.FIPS.isna().sum())\n\n# Removing NaN\nus_confirmed.dropna(inplace=True)\nus_deceased.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshaping dataframes. Converting Date representing columns and their values into separate column \nus_confirmedDF = pd.melt(us_confirmed, id_vars=[\"FIPS\"], var_name=\"Date\", value_name=\"Confirmed\")\nus_deceasedDF = pd.melt(us_deceased, id_vars=[\"FIPS\"],var_name=\"Date\", value_name=\"Deceased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_confirmedDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_deceasedDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging the dataframes\ncompleteDF = pd.merge(left=us_confirmedDF, right=us_deceasedDF, how='inner', on=[\"FIPS\", \"Date\"])\n\n# Changing datatypes of columns to more appropriate format\ncompleteDF['Confirmed'] = completeDF['Confirmed'].astype('int')\ncompleteDF['Deceased'] = completeDF['Deceased'].astype('int')\ncompleteDF['FIPS'] = completeDF[\"FIPS\"].astype('int')\n\n# Converting the Date column into proper datetime formate and sort\ncompleteDF.Date = pd.to_datetime(completeDF.Date)\ncompleteDF = completeDF.sort_values(by=[\"Date\", \"FIPS\"]).reset_index(drop=True)\n\ncompleteDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latestDate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dataframes only consisting current, 2 weeks old and a month old date data\nlatestDate = date.today() - timedelta(days=1)\ntwoWeekDate = date.today() - timedelta(weeks=2)\nmonthOldDate = date.today() - timedelta(weeks=4)\n\nlatestDateDF = completeDF[completeDF['Date'] == np.datetime64(latestDate)].reset_index(drop=True)\ntwoWeekDateDF = completeDF[completeDF['Date'] == np.datetime64(twoWeekDate)].reset_index(drop=True)\nmonthOldDateDF = completeDF[completeDF['Date'] == np.datetime64(monthOldDate)].reset_index(drop=True)\n\nlatestDateDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"latestDate: \", latestDate)\nprint(\"twoWeekDate: \", twoWeekDate)\nprint(\"monthOldDate: \", monthOldDate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting countyFIPS column name to FIPS to be used as common name accross all the DFs \nus_population.rename(columns = {'countyFIPS':'FIPS'}, inplace = True)\nus_population","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Final DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will add all our dataframes into finalDF. We want all the columns from DFs except Date column.\nfinalDF = pd.merge(left=us_population, right=latestDateDF.loc[:, [\"FIPS\", \"Confirmed\", \"Deceased\"]], how='left', on=[\"FIPS\"])\nfinalDF.rename(columns = {'Confirmed':'T_Confirmed', 'Deceased':'T_Deceased'}, inplace = True)\n\nfinalDF = pd.merge(left=finalDF, right=twoWeekDateDF.loc[:, [\"FIPS\", \"Confirmed\", \"Deceased\"]], how='left', on=[\"FIPS\"])\nfinalDF.rename(columns = {'Confirmed':'Two_Week_Old_Confirmed', 'Deceased':'Two_Week_Old_Deceased'}, inplace = True)\n\nfinalDF = pd.merge(left=finalDF, right=monthOldDateDF.loc[:, [\"FIPS\", \"Confirmed\", \"Deceased\"]], how='left', on=[\"FIPS\"])\nfinalDF.rename(columns = {'Confirmed':'Month_Old_Confirmed', 'Deceased':'Month_Old_Deceased'}, inplace = True)\n\nfinalDF.dropna(inplace=True)\nfinalDF = finalDF.reset_index(drop=True)\nfinalDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Per capita stats\nfinalDF['Conf_100k'] = round(finalDF['T_Confirmed'] * 100000 / finalDF['population'], 2)\nfinalDF['Dec_100k'] = round(finalDF['T_Deceased'] * 100000 / finalDF['population'], 2)\n\n# Percentage increase and decrease for two weekold and month old stats\nfinalDF['%_Conf_Inc_BW'] = round((finalDF['T_Confirmed'] - finalDF['Two_Week_Old_Confirmed']) * 100 / finalDF['Two_Week_Old_Confirmed'], 2)\nfinalDF['%_Dec_Inc_BW'] = round((finalDF['T_Deceased'] - finalDF['Two_Week_Old_Deceased']) * 100 / finalDF['Two_Week_Old_Deceased'], 2)\n\nfinalDF['%_Conf_Inc_M'] = round((finalDF['T_Confirmed'] - finalDF['Month_Old_Confirmed']) * 100 / finalDF['Month_Old_Confirmed'], 2)\nfinalDF['%_Dec_Inc_M'] = round((finalDF['T_Deceased'] - finalDF['Month_Old_Deceased']) * 100 / finalDF['Month_Old_Deceased'], 2)\n\n# Dropping unwanted columns\nfinalDF.drop([\"Two_Week_Old_Confirmed\", \"Two_Week_Old_Deceased\", \"Month_Old_Confirmed\", \"Month_Old_Deceased\"], axis=1, inplace=True)\n\n# Removing NaN occure when a number is divided by 0. This exists since some deceased cases might be 0 from start.\nfinalDF = finalDF.fillna(0)\nfinalDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing incorrect FIPS by merging finalDF with us_county based on County Name and State. \n# This will add correct FIPS where they should be\nfinalDF = finalDF.drop(columns=['FIPS'])\nfinalDF = pd.merge(left=us_county, right=finalDF, how='left', on=[\"County Name\",\"State\"])\nfinalDF.rename(columns = {'County Name':'County_Name', 'Total_Deceased':\"T_Deceased\"}, inplace = True)\nfinalDF.dropna(inplace=True)\nfinalDF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Choropleths","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases by County","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n    counties = json.load(response)\n\n\nfig = px.choropleth(finalDF, geojson=counties, locations='FIPS', color='T_Confirmed',\n                           color_continuous_scale=\"Plasma_r\",\n                           range_color=(0, 1000),\n                           scope=\"usa\",\n                           hover_name=\"County_Name\",\n                           hover_data=[\"T_Confirmed\", \"T_Deceased\", \"Conf_100k\", \"%_Conf_Inc_BW\", \"%_Conf_Inc_M\"],\n                           labels={\n                               'T_Confirmed':'Total Confirmed Cases',\n                               'T_Deceased':'Total Deceased',\n                               'Conf_100k':'Confirmed Cases per 100,000',\n                               '%_Conf_Inc_BW': '% Increase in Cases Bi-Weekly',\n                               '%_Conf_Inc_M':'% Increase in Cases Monthly'}\n                          )\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deceased Cases by County","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n    counties = json.load(response)\n\n\nfig = px.choropleth(finalDF, geojson=counties, locations='FIPS', color='T_Deceased',\n                           color_continuous_scale=\"Inferno_r\",\n                           range_color=(0, 50),\n                           scope=\"usa\",\n                           hover_name=\"County_Name\",\n                           hover_data=[\"T_Confirmed\", \"T_Deceased\", \"Dec_100k\", \"%_Dec_Inc_BW\", \"%_Dec_Inc_M\"],\n                           labels={\n                               'T_Confirmed':'Total Confirmed Cases',\n                               'T_Deceased':'Total Deceased',\n                               'Dec_100k':'Deceased Cases per 100,000',\n                               '%_Dec_Inc_BW': '% Increase in Deaths Bi-Weekly',\n                               '%_Dec_Inc_M':'% Increase in Deaths Monthly'}\n                          )\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tree Maps","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases US County wise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(finalDF.sort_values(by='T_Confirmed', ascending=False).reset_index(drop=True), \n                 path=[\"County_Name\"], values=\"T_Confirmed\", height=700,\n                 title='Number of Confirmed Cases',\n                 color_discrete_sequence = px.colors.qualitative.Dark2)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deceased Cases per US State-County wise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(finalDF.sort_values(by='T_Deceased', ascending=False).reset_index(drop=True), \n                 path=[\"State\", \"County_Name\"], values=\"T_Deceased\", height=700,\n                 title='Total Deceased',\n                 color_discrete_sequence = px.colors.qualitative.Dark24)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}